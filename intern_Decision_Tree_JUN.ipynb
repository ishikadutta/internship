{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pydot\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"BANKNIFTYFUTALL.csv\")\n",
    "feature_cols_JUN = ['trade', 'event', 'ob', 'spreadreturn','niftyidevent', 'niftyidob','niftyidindex']\n",
    "\n",
    "#data.dropna(subset=['return800'], axis=0)\n",
    "\n",
    "data.drop([data.index[457897]],inplace=True)\n",
    "#data.isnull().sum(axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           trade     event        ob  spreadreturn  niftyidevent  niftyidob  \\\n",
      "0       1.887790 -0.480131  0.691948      0.340223      0.559968  -1.553040   \n",
      "1       1.887790 -0.416937  1.592650     -0.125436      0.537654  -1.530060   \n",
      "2       2.502120  0.159981  0.725512      0.350363      0.537654  -1.605290   \n",
      "3       1.935330  0.274211  1.238070     -0.278274      1.031850  -0.012095   \n",
      "4       1.759630  0.847955  0.864624      0.287151      0.733237   1.780540   \n",
      "5       1.759630  0.707320  0.430883     -1.020880     -0.720371   0.510119   \n",
      "6       1.759630  0.625122  0.137820      0.334935      0.938224   1.195730   \n",
      "7       1.970140  1.519540  1.051380      0.339038      0.739260  -0.313306   \n",
      "8       1.970140  1.464540  0.948582      0.321138      0.278489  -1.853770   \n",
      "9       1.970140  1.372050  0.608076      1.129120      0.408007  -1.216400   \n",
      "10      1.469680  1.456080 -0.992390     -1.415430      0.408007  -1.216400   \n",
      "11      1.469680  1.114180 -1.069940     -0.532296      0.523794   1.530020   \n",
      "12      1.469680  1.085190 -0.805662     -0.504471      0.501449   1.023820   \n",
      "13      1.469680  1.001710 -0.604779     -0.481999      0.109928   0.853988   \n",
      "14      1.469680  1.034890 -0.289888      0.389354      2.095600   2.425330   \n",
      "15      1.469680  0.956612 -0.206890      1.264970      2.095600   2.425330   \n",
      "16      1.226340  0.562763 -0.766964     -1.480300      0.900106   1.102710   \n",
      "17      1.104790  0.389644 -1.072280     -0.453716      1.175240   1.336720   \n",
      "18      1.459970  0.213878 -0.876219      0.479710     -3.000000  -3.000000   \n",
      "19      1.459970 -0.004972 -0.388748     -1.152100     -3.000000  -3.000000   \n",
      "20      1.106050  0.436124 -0.508776      0.589258     -3.000000  -1.811300   \n",
      "21      0.789048  0.291899 -1.083420     -1.205410     -3.000000   0.051483   \n",
      "22      0.789048  0.272997 -0.646166     -1.094170     -3.000000   0.702615   \n",
      "23      0.811668  0.627675  0.292765      0.705658     -3.000000   0.047628   \n",
      "24      0.612338  0.450798 -1.364300     -0.151493     -3.000000  -1.769370   \n",
      "25      0.612338  0.457261 -1.344410     -0.145320     -3.000000  -1.712070   \n",
      "26      0.612338  0.612798 -0.842318     -0.142605     -3.000000  -3.000000   \n",
      "27      0.496193  0.587340 -0.905007     -2.135510     -3.000000  -3.000000   \n",
      "28      0.496193  0.642995 -0.778414     -0.129781     -3.000000  -3.000000   \n",
      "29      0.415728  0.591053 -0.736604     -0.124870     -3.000000  -2.692520   \n",
      "...          ...       ...       ...           ...           ...        ...   \n",
      "457867  0.693710 -1.452340 -0.496409     -0.183510     -1.634560   0.107422   \n",
      "457868 -0.223387 -0.387507  0.301648     -0.521434     -1.849930   1.396690   \n",
      "457869 -0.223387 -1.463950  0.786177     -0.508491     -1.892510   0.993368   \n",
      "457870 -0.223387 -1.435600  0.616971      0.227139     -1.938140   0.756390   \n",
      "457871  0.693710 -1.888260 -1.099430     -0.159324     -1.866220   0.817090   \n",
      "457872  0.693710 -0.507056 -0.411176     -0.120730     -1.866220   1.121970   \n",
      "457873  0.387461 -0.363933  0.384291     -0.550250     -1.866220   1.121970   \n",
      "457874  0.095345 -0.998994  0.752635     -0.558364     -1.836220   1.060960   \n",
      "457875  0.095345 -0.653866  0.803932      0.213203     -1.836220   1.145070   \n",
      "457876  0.095345 -0.230526  0.677845      0.968618     -1.836220   1.145070   \n",
      "457877  0.564583 -0.272030  0.701395      0.271227     -1.836220   1.145070   \n",
      "457878  0.722408  0.149568  0.798822      0.895664     -1.770680   1.016610   \n",
      "457879  0.722408  0.672929  0.408998      0.822828     -1.730960   0.980395   \n",
      "457880  0.722408  1.867790  0.874732      0.083414     -1.480340  -0.323208   \n",
      "457881  0.722408  1.967500  0.698358      0.675000     -1.471490  -0.321494   \n",
      "457882  0.722408  1.855110  0.764372      0.608680     -1.471490  -0.228238   \n",
      "457883  0.722408  1.797140  0.192257      1.874900     -1.471490  -0.228238   \n",
      "457884  0.693710  0.379142  0.200680      2.297130     -1.451640  -0.396752   \n",
      "457885  0.722408  1.743150  0.013234     -0.792389     -1.134470  -0.365960   \n",
      "457886  0.693710  0.253253 -1.059360     -0.205140     -1.136540  -0.365959   \n",
      "457887  0.722408  1.497890  0.131952     -0.184375     -1.136540  -0.365959   \n",
      "457888  0.693710  0.018073 -0.661961     -0.241907     -0.997992  -0.469620   \n",
      "457889  0.693710  0.149870 -0.245259      0.561471     -1.109410  -0.302510   \n",
      "457890  0.693710 -0.168752 -0.794770      0.567436     -1.052720  -0.353408   \n",
      "457891  0.693710  0.174396 -1.207380     -0.223881     -1.365030  -0.586463   \n",
      "457892  0.693710  0.149907 -0.997353     -0.168293     -1.370840  -0.240215   \n",
      "457893  0.693710  0.840055 -0.143478      2.199010     -1.374230  -0.178190   \n",
      "457894  0.722408 -0.695570  0.222023     -0.159677     -1.203450   0.039303   \n",
      "457895  0.693710  0.010195 -0.529087     -0.107718     -1.405500  -0.076190   \n",
      "457896  0.693710 -0.026227 -0.916923     -0.101948     -1.526520   1.097500   \n",
      "\n",
      "        niftyidindex  \n",
      "0            0.00000  \n",
      "1            0.00000  \n",
      "2            0.00000  \n",
      "3            0.00000  \n",
      "4            0.00000  \n",
      "5            0.00000  \n",
      "6            0.00000  \n",
      "7            0.00000  \n",
      "8            0.00000  \n",
      "9            0.00000  \n",
      "10           0.00000  \n",
      "11           0.00000  \n",
      "12           0.00000  \n",
      "13           0.00000  \n",
      "14           0.00000  \n",
      "15           0.00000  \n",
      "16           0.00000  \n",
      "17           0.00000  \n",
      "18           0.00000  \n",
      "19           0.00000  \n",
      "20           0.00000  \n",
      "21           0.00000  \n",
      "22           0.00000  \n",
      "23           0.00000  \n",
      "24           0.00000  \n",
      "25           0.00000  \n",
      "26           0.00000  \n",
      "27           0.00000  \n",
      "28           0.00000  \n",
      "29           0.00000  \n",
      "...              ...  \n",
      "457867      -2.20535  \n",
      "457868      -2.20535  \n",
      "457869      -2.20535  \n",
      "457870      -2.20535  \n",
      "457871      -2.20535  \n",
      "457872      -2.20535  \n",
      "457873      -2.20535  \n",
      "457874      -2.20535  \n",
      "457875      -2.20535  \n",
      "457876      -2.20535  \n",
      "457877      -2.20535  \n",
      "457878      -2.20535  \n",
      "457879      -2.20535  \n",
      "457880      -2.20535  \n",
      "457881      -2.20535  \n",
      "457882      -2.20535  \n",
      "457883      -2.20535  \n",
      "457884      -2.20535  \n",
      "457885      -2.20535  \n",
      "457886      -2.20535  \n",
      "457887      -2.20535  \n",
      "457888      -2.20535  \n",
      "457889      -2.20535  \n",
      "457890      -2.20535  \n",
      "457891      -2.20535  \n",
      "457892      -2.20535  \n",
      "457893      -2.20535  \n",
      "457894      -2.20535  \n",
      "457895      -2.20535  \n",
      "457896      -2.20535  \n",
      "\n",
      "[457897 rows x 7 columns]\n",
      "0         19.180220\n",
      "1         19.505399\n",
      "2         21.961185\n",
      "3         21.821542\n",
      "4         17.728398\n",
      "5         17.333114\n",
      "6         17.425443\n",
      "7          6.489488\n",
      "8          6.373442\n",
      "9          5.005910\n",
      "10         0.741245\n",
      "11        -0.857063\n",
      "12         0.787564\n",
      "13         0.393779\n",
      "14        -0.625391\n",
      "15         2.339333\n",
      "16        -5.303959\n",
      "17        -3.683062\n",
      "18        -4.099709\n",
      "19        -2.409248\n",
      "20        -3.497435\n",
      "21        -2.848996\n",
      "22        -2.455392\n",
      "23        -6.066949\n",
      "24         6.511805\n",
      "25        -0.672001\n",
      "26        -6.094156\n",
      "27        13.323570\n",
      "28        -6.881467\n",
      "29        -4.610665\n",
      "            ...    \n",
      "457867    -7.123028\n",
      "457868    -0.613627\n",
      "457869    -0.047205\n",
      "457870     0.354047\n",
      "457871    -6.203503\n",
      "457872    -5.896838\n",
      "457873     0.637260\n",
      "457874     0.778884\n",
      "457875     1.628607\n",
      "457876     6.703109\n",
      "457877     1.982605\n",
      "457878     7.859557\n",
      "457879     1.699352\n",
      "457880     6.891571\n",
      "457881     6.324991\n",
      "457882     6.372193\n",
      "457883     6.277375\n",
      "457884     0.613254\n",
      "457885     4.908334\n",
      "457886    -7.051538\n",
      "457887     4.932002\n",
      "457888    -0.424530\n",
      "457889    -6.085135\n",
      "457890    -6.132278\n",
      "457891    -6.697955\n",
      "457892    -6.320844\n",
      "457893    -6.250339\n",
      "457894    -0.377606\n",
      "457895    -6.132480\n",
      "457896    -6.438983\n",
      "Name: return800, Length: 457897, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X= data[feature_cols_JUN]\n",
    "Y = data.return800\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying Linear Regression by dividing the dataset into two parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "Index_label1 = X[X['ob']<-0.527].index.tolist() \n",
    "x_model_1 = X.iloc[Index_label1]\n",
    "y_model_1=Y.iloc[Index_label1]\n",
    "\n",
    "Index_label2 = X[X['ob']>=-0.527].index.tolist()\n",
    "x_model_2=X.iloc[Index_label2]\n",
    "y_model_2 = Y.iloc[Index_label2]\n",
    "\n",
    "reg1= LinearRegression()\n",
    "reg1.fit(x_model_1,y_model_1)\n",
    "reg2= LinearRegression()\n",
    "reg2.fit(x_model_2,y_model_2)\n",
    "reg= LinearRegression()\n",
    "reg.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comparing the scores of the model Before and After split\n",
    "- It can be observed that score of model after splitting has increased drastically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_sq1  0.08174825258539253\n",
      "r_sq2  0.011964269512279468\n",
      "r_sq  0.0031935721278721907\n",
      "correlation_after_split : -0.000617111161783011\n",
      "correlation_after_spit : -0.0001303789433374712\n",
      "corr_before_split: 0.05651169903544089\n"
     ]
    }
   ],
   "source": [
    "r_sq1 = reg1.score(x_model_1,y_model_1)\n",
    "print(\"r_sq1 \",r_sq1)\n",
    "r_sq2 = reg2.score(x_model_2,y_model_2)\n",
    "print(\"r_sq2 \",r_sq2)\n",
    "r_sq = reg.score(X,Y)\n",
    "print(\"r_sq \",r_sq)\n",
    "\n",
    "predict1 = reg1.predict(x_model_1)\n",
    "predict2 = reg2.predict(x_model_2)\n",
    "pred = reg.predict(X)\n",
    "\n",
    "pred= pd.Series(data=pred)\n",
    "predict1 = pd.Series(data=predict1)\n",
    "predict2 = pd.Series(data=predict2)\n",
    "\n",
    "correlation1 = y_model_1.corr(predict1)\n",
    "correlation2 = y_model_2.corr(predict2)\n",
    "corre= Y.corr(pred)\n",
    "print(\"correlation_after_split :\",correlation1)\n",
    "print(\"correlation_after_spit :\",correlation2)\n",
    "print(\"corr_before_split:\",corre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculating the correlation between predicted and actual values manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "457897\n",
      "457897\n",
      "0.06055169105064174\n"
     ]
    }
   ],
   "source": [
    "l1=[]\n",
    "l2=[]\n",
    "for i in range(len(Y)):\n",
    "    if(Y[i]>0):\n",
    "        l1.append(1)\n",
    "    elif(Y[i]<0):\n",
    "        l1.append(-1)\n",
    "    else:\n",
    "        l1.append(0)\n",
    "        \n",
    "for i in range(len(pred)):\n",
    "    if(pred[i]>0):\n",
    "        l2.append(1)\n",
    "    elif(pred[i]<0):\n",
    "        l2.append(-1)\n",
    "    else:\n",
    "        l2.append(0)\n",
    "\n",
    "print(len(l1))\n",
    "print(len(l2))\n",
    "pred= pd.Series(data=pred)\n",
    "pred1 = pd.Series(data=l1)\n",
    "pred2 = pd.Series(data=l2)\n",
    "corr1 = y_model_1.corr(pred1)\n",
    "corr2 = y_model_2.corr(pred2)\n",
    "co= pred1.corr(pred2)\n",
    "print(co)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying Decision Tree Regression for our dataset\n",
    "- Decision trees regression normally use mean squared error (MSE) to decide to split a node in two or more sub-nodes\n",
    "- Here, many different values of test split and train split are taken to check if the model is overfitting or not\n",
    "- Overfitting occurs when on changing the size of dataset and it parameters the score of train set increases whereas the score of test set decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse 4.01689595180483\n",
      "score for train 0.08252301423604103\n",
      "score fro test 0.08137200305545478\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test= train_test_split(X,Y,test_size=0.3,random_state=1)\n",
    "\n",
    "dt = DecisionTreeRegressor(max_depth=4,min_samples_split=2)\n",
    "dt.fit(x_train,y_train)\n",
    "\n",
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "y_pred = dt.predict(x_test)\n",
    "mse=mean_squared_error(y_test,y_pred)\n",
    "rmse= np.sqrt(mse)\n",
    "print(\"rmse\",rmse)\n",
    "\n",
    "score_train=dt.score(x_train,y_train)\n",
    "print(\"score for train\",score_train)\n",
    "print(\"score fro test\",dt.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Below are some reults with different parameters\n",
    "##for depth=1, split at 0.2,0.3,0.4,0.5\n",
    "- rmse 4.145847605849474\n",
    "- score for train 0.02226440625077197\n",
    "- score fro test 0.02283569743557245\n",
    "\n",
    "- rmse 4.144504581414699\n",
    "- score for train 0.022507148317065573\n",
    "- score fro test 0.022079027012244956\n",
    "\n",
    "- rmse 4.144577992334352\n",
    "- score for train 0.022997720054378945\n",
    "- score fro test 0.021442723908110643\n",
    "\n",
    "- rmse 4.148930982547038\n",
    "- score for train 0.02281081351563241\n",
    "- score fro test 0.021948244176629328\n",
    "\n",
    "##for depth=2 spit at 0.2,0.3,0.4,0.5\n",
    "- rmse 4.073192484629125\n",
    "- score for train 0.0570762952822117\n",
    "- score fro test 0.05678479664169356\n",
    "\n",
    "- rmse 4.07156993702865\n",
    "- score for train 0.05735271793947039\n",
    "- score fro test 0.05619492063668153\n",
    "\n",
    "- rmse 4.071692793025529\n",
    "- score for train 0.057895660733723764\n",
    "- score fro test 0.05555727862956494\n",
    "\n",
    "- rmse 4.074746247753332\n",
    "- score for train 0.05716523872980195\n",
    "- score fro test 0.056611553379002255\n",
    "\n",
    "##for depth=3, split at 0.2,0.3,0.4\n",
    "- rmse 4.0468492820746285\n",
    "- score for train 0.06929428369582413\n",
    "- score fro test 0.06894575381720713\n",
    "\n",
    "- rmse 4.046364697810738\n",
    "- score for train 0.06967525494007609\n",
    "- score fro test 0.06784408802936615\n",
    "\n",
    "- rmse 4.046033401840228\n",
    "- score for train 0.07049563186003682\n",
    "- score fro test 0.06742333381827836\n",
    "\n",
    "##for depth=4\n",
    "- rmse 4.017543554643882\n",
    "- score for train 0.08223427935788684\n",
    "- score fro test 0.08238160255808935\n",
    "\n",
    "- rmse 4.01689595180483\n",
    "- score for train 0.08252301423604103\n",
    "- score fro test 0.08137200305545478\n",
    "\n",
    "- rmse 4.0185934043951566\n",
    "- score for train 0.083427696916616\n",
    "- score fro test 0.08002981729724767\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying DecisionTreeRegressor on the data by changing the value of parameters like max_depth and min_samples_split\n",
    "- Minimum samples for a node split: Defines the minimum number of samples (or observations) which are required in a node to be considered for splitting.\n",
    "\n",
    "- Minimum samples for a terminal node (leaf): Defines the minimum samples (or observations) required in a terminal node or leaf.\n",
    "\n",
    "- Maximum depth of the tree (vertical depth): Used to control over-fitting as higher depth will allow the model to learn relations very specific to a particular sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((274738, 7), (183159, 7), (274738,), (183159,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test= train_test_split(X,Y,test_size=0.4,random_state=1)\n",
    "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=1, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor(max_depth=1,min_samples_split=2)\n",
    "dt.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.31432045])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.predict([[1.970140, 1.519540,  1.051380,0.339038   , 0.739260,  -0.313306  , 0.00000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.144577992334352"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "y_pred = dt.predict(x_test)\n",
    "mse=mean_squared_error(y_test,y_pred)\n",
    "rmse= np.sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02144272390811064"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022997720054378945"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_train=dt.score(x_train,y_train)\n",
    "score_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021442723908110643"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score=dt.score(x_test,y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=2, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt2 = DecisionTreeRegressor(max_depth=2,min_samples_split=2)\n",
    "dt2.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse 4.071692793025529\n",
      "score for train 0.05789566073372354\n",
      "score fro test 0.05555727862956494\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "y_pred = dt2.predict(x_test)\n",
    "mse=mean_squared_error(y_test,y_pred)\n",
    "rmse= np.sqrt(mse)\n",
    "print(\"rmse\",rmse)\n",
    "\n",
    "score_train=dt2.score(x_train,y_train)\n",
    "print(\"score for train\",score_train)\n",
    "print(\"score fro test\",dt2.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=3, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt3 = DecisionTreeRegressor(max_depth=3,min_samples_split=2)\n",
    "dt3.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse 4.046033401840228\n",
      "score for train 0.07049563186003682\n",
      "score fro test 0.06742333381827825\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "y_pred = dt3.predict(x_test)\n",
    "mse=mean_squared_error(y_test,y_pred)\n",
    "rmse= np.sqrt(mse)\n",
    "print(\"rmse\",rmse)\n",
    "\n",
    "score_train=dt3.score(x_train,y_train)\n",
    "print(\"score for train\",score_train)\n",
    "print(\"score fro test\",dt3.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=4, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt4 = DecisionTreeRegressor(max_depth=4,min_samples_split=2)\n",
    "dt4.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse 4.0185934043951566\n",
      "score for train 0.083427696916616\n",
      "score fro test 0.08002981729724767\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "y_pred = dt4.predict(x_test)\n",
    "mse=mean_squared_error(y_test,y_pred)\n",
    "rmse= np.sqrt(mse)\n",
    "print(\"rmse\",rmse)\n",
    "\n",
    "score_train=dt4.score(x_train,y_train)\n",
    "print(\"score for train\",score_train)\n",
    "print(\"score fro test\",dt4.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt5 = DecisionTreeRegressor(max_depth=5,min_samples_split=2)\n",
    "dt5.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse 4.004325911148841\n",
      "score for train 0.09143252653695733\n",
      "score for test 0.08655068993141246\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "y_pred = dt5.predict(x_test)\n",
    "mse=mean_squared_error(y_test,y_pred)\n",
    "rmse= np.sqrt(mse)\n",
    "print(\"rmse\",rmse)\n",
    "\n",
    "score_train=dt5.score(x_train,y_train)\n",
    "print(\"score for train\",score_train)\n",
    "print(\"score for test\",dt5.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=6, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=3, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt6 = DecisionTreeRegressor(max_depth=6,min_samples_split=3)\n",
    "dt6.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse 3.991361685485709\n",
      "score for train 0.09704695337027669\n",
      "score for test 0.09301379765271489\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "y_pred = dt6.predict(x_test)\n",
    "mse=mean_squared_error(y_test,y_pred)\n",
    "rmse= np.sqrt(mse)\n",
    "print(\"rmse\",rmse)\n",
    "\n",
    "score_train=dt6.score(x_train,y_train)\n",
    "print(\"score for train\",score_train)\n",
    "print(\"score for test\",dt6.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Constructing the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals.six import StringIO\n",
    "from sklearn.tree import export_graphviz  \n",
    "dot_data = StringIO()\n",
    "export_graphviz(dt, out_file='dot_data_rec.dot',  \n",
    "                         feature_names=['trade', 'event', 'ob', 'spreadreturn','niftyidevent', 'niftyidob','niftyidindex'],  \n",
    "                         class_names='return800',  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "#graph = pydot.graph_from_dot_data(dot_data.getvalue()) \n",
    "#Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06922466540674233"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#at maxdepth=1, got score =0.022393481563377282\n",
    "#at maxdepth=2, got score= 0.05670479000003592\n",
    "#at maxdepth=3, got score= 0.0690640327405383\n",
    "#at maxdepth=4, got score= 0.08066786342007692\n",
    "#when max_depth value not specified, got score= 0.9555801579283528(overfitting)\n",
    "score=dt3.score(X,Y)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = BaggingRegressor(base_estimator=LinearRegression(),n_estimators=10, random_state=0).fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003192241424595621"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.score(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
